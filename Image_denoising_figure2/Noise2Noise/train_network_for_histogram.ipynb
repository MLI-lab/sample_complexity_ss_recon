{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "from utils.main_function_helpers import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import pathlib\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import glob\n",
    "from torch.serialization import default_restore_location\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "import utils\n",
    "import models \n",
    "\n",
    "from utils.data_helpers.load_datasets_helpers import *\n",
    "from utils.meters import *\n",
    "from utils.progress_bar import *\n",
    "from utils.noise_model import get_noise\n",
    "from utils.metrics import ssim,psnr\n",
    "from utils.util_calculate_psnr_ssim import calculate_psnr,calculate_ssim\n",
    "from utils.test_metrics import *\n",
    "\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the path to ImageNet dataset and the training set size\n",
    "\n",
    "#path_to_ImageNet_train = '../../../../../media/hdd1/ImageNet/ILSVRC/Data/CLS-LOC/'\n",
    "path_to_ImageNet_train = '../../'\n",
    "train_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters during training \n",
    "lr = 6.4e-4\n",
    "fix_noise = True\n",
    "noise_std = 25\n",
    "batch_size = 1\n",
    "patch_size = 128\n",
    "val_crop = False\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "device = torch.device('cuda') if (torch.cuda.is_available() and USE_CUDA) else torch.device('cpu')\n",
    "\n",
    "model = models.unet_fastMRI(\n",
    "            in_chans=3,\n",
    "            chans = 128,\n",
    "            num_pool_layers = 2,\n",
    "            drop_prob = 0.0,\n",
    "            residual_connection = True,\n",
    "        ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "trainset = ImagenetSubdataset(train_size,path_to_ImageNet_train,mode='train',patch_size=patch_size,val_crop=val_crop)\n",
    "train_loader = DataLoader(trainset, batch_size= batch_size, shuffle=True, num_workers=8, pin_memory=True,generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for one epoch\n",
    "\n",
    "train_bar3 = ProgressBar(train_loader)\n",
    "true_grad = []\n",
    "\n",
    "param = list(model.parameters())\n",
    "\n",
    "        \n",
    "for inputs, noise_seed in train_bar3:\n",
    "    \n",
    "    model.train() #Sets the module in training mode.\n",
    "    inputs = inputs.to(device)\n",
    "    noise = get_noise(inputs,noise_seed, fix_noise = fix_noise, noise_std = noise_std/255.)\n",
    "                    \n",
    "\n",
    "    model.zero_grad()    \n",
    "    noisy_inputs = noise + inputs\n",
    "    outputs = model(noisy_inputs)\n",
    "\n",
    "    loss_sup = F.mse_loss(outputs, inputs, reduction=\"sum\") / torch.prod(torch.tensor(inputs.size())) #(inputs.size(0) * 2) \n",
    "    loss_sup.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the true gradient\n",
    "\n",
    "train_bar = ProgressBar(train_loader)\n",
    "true_grad = []\n",
    "\n",
    "param = list(model.parameters())\n",
    "k=0\n",
    "        \n",
    "for inputs, noise_seed in train_bar:\n",
    "    \n",
    "    k=k+1\n",
    "    \n",
    "    model.train() #Sets the module in training mode.\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    noise = get_noise(inputs,noise_seed, fix_noise = fix_noise, noise_std = noise_std/255.)\n",
    "                    \n",
    "\n",
    "    noisy_inputs = noise + inputs\n",
    "    outputs = model(noisy_inputs)\n",
    "\n",
    "    loss_sup = F.mse_loss(outputs, inputs, reduction=\"sum\") / torch.prod(torch.tensor(inputs.size())) #(inputs.size(0) * 2)\n",
    "    \n",
    "    #model.zero_grad()    \n",
    "    loss_sup.backward()\n",
    "\n",
    "    #for p in param:\n",
    "    #    if k == 1:\n",
    "    #        p.grad_true = p.grad\n",
    "    #    else:\n",
    "    #        p.grad_true = p.grad_true + p.grad\n",
    "    #    p.grad = None\n",
    "    \n",
    "#for p in param:\n",
    "#    p.grad_true = p.grad_true / train_size\n",
    "#    true_grad.append(p.grad_true)\n",
    "\n",
    "length = torch.zeros(1).to(device)\n",
    "for p in param:\n",
    "    p.grad = p.grad / train_size\n",
    "    true_grad.append(p.grad)\n",
    "    length += torch.sum(torch.square(p.grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bar2 = ProgressBar(train_loader)\n",
    "normalized_diff_tn25 = []\n",
    "normalized_diff_tn50 = []\n",
    "normalized_diff_tn0 = []\n",
    "#length = 0\n",
    "for inputs, noise_seed in train_bar2:\n",
    "    \n",
    "    model.train() #Sets the module in training mode.\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    noise = get_noise(inputs,noise_seed, fix_noise = fix_noise, noise_std = noise_std/255.)\n",
    "    noise_target_tn25 = get_noise(inputs,torch.mul(noise_seed,10),fix_noise = fix_noise, noise_std = 25/255.)\n",
    "    noise_target_tn50 = get_noise(inputs,torch.mul(noise_seed,100),fix_noise = fix_noise, noise_std = 50/255.)\n",
    "                \n",
    "\n",
    "    noisy_targets_tn25 = noise_target_tn25 + inputs \n",
    "    noisy_targets_tn50 = noise_target_tn50 + inputs \n",
    "\n",
    "    noisy_inputs = noise + inputs\n",
    "    outputs = model(noisy_inputs)\n",
    "    # In loss function, I changed outputs to noisy_targets for self-supervision\n",
    "    loss_tn50 = F.mse_loss(outputs, noisy_targets_tn50, reduction=\"sum\") / torch.prod(torch.tensor(inputs.size())) #(inputs.size(0) * 2)\n",
    "    loss_tn25 = F.mse_loss(outputs, noisy_targets_tn25, reduction=\"sum\") / torch.prod(torch.tensor(inputs.size())) #(inputs.size(0) * 2)\n",
    "    loss_sup = F.mse_loss(outputs, inputs, reduction=\"sum\") / torch.prod(torch.tensor(inputs.size())) #(inputs.size(0) * 2)\n",
    "\n",
    "    param = list(model.parameters())\n",
    "    \n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss_tn50.backward(retain_graph=True)\n",
    "    \n",
    "    \n",
    "    for p in param:\n",
    "        p.grad_tn50 = p.grad\n",
    "        p.grad = None\n",
    "    \n",
    "    \n",
    "    loss_tn25.backward(retain_graph=True)\n",
    "    \n",
    "    \n",
    "    for p in param:\n",
    "        p.grad_tn25 = p.grad\n",
    "        p.grad = None\n",
    "    \n",
    "    \n",
    "    loss_sup.backward()\n",
    "\n",
    "    for p in param:\n",
    "        p.grad_sup = p.grad\n",
    "        p.grad = None\n",
    "    \n",
    "    \n",
    "    diff_tn25 = torch.zeros(1).to(device)\n",
    "    diff_tn50 = torch.zeros(1).to(device)\n",
    "    diff_tn0 = torch.zeros(1).to(device)\n",
    "    #length = torch.zeros(1).to(device)\n",
    "    for idx,p in enumerate(param):\n",
    "        diff_tn0 += torch.sum(torch.square(torch.sub(p.grad_sup,true_grad[idx])))\n",
    "        diff_tn25 += torch.sum(torch.square(torch.sub(p.grad_tn25,true_grad[idx])))\n",
    "        diff_tn50 += torch.sum(torch.square(torch.sub(p.grad_tn50,true_grad[idx])))\n",
    "        #length += torch.sum(torch.square(true_grad[idx]))\n",
    "        \n",
    "\n",
    "        \n",
    "    normalized_diff_tn25.append(torch.div(diff_tn25,length).item())\n",
    "    normalized_diff_tn50.append(torch.div(diff_tn50,length).item())\n",
    "    normalized_diff_tn0.append(torch.div(diff_tn0,length).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the histograms\n",
    "# Create a histogram of the data with three different colors\n",
    "#plt.hist([normalized_diff_tn0, normalized_diff_tn25, normalized_diff_tn50], bins=int(np.sqrt(train_size)), alpha=0.5, label=['Sup.', '$\\sigma = 25$', '$\\sigma = 50$'], color=['red', 'green', 'blue'])\n",
    "binwidth = 0.05 #1/int(np.sqrt(train_size))\n",
    "data = []\n",
    "for c in normalized_diff_tn0:\n",
    "    data.append(c)\n",
    "for c in normalized_diff_tn25:\n",
    "    data.append(c)\n",
    "for c in normalized_diff_tn50:\n",
    "    data.append(c)\n",
    "plt.hist(normalized_diff_tn0,bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, label='Sup.', color='red')\n",
    "plt.hist(normalized_diff_tn25,bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, label='$\\sigma = 25$', color='green')\n",
    "plt.hist(normalized_diff_tn50,bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, label='$\\sigma = 50$', color='blue')\n",
    "# Add a legend to the plot\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Normalized Difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Stochastic Gradients')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of the plots\n",
    "print('Mean of supervised gradients: ' + str(np.mean(normalized_diff_tn0)))\n",
    "print('Mean of gradients when target noise = 25 : ' + str(np.mean(normalized_diff_tn25)))\n",
    "print('Mean of gradients when target noise = 50 : ' + str(np.mean(normalized_diff_tn50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
